{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS Experiments to verify theory for L-inf norm - CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import sys, os, gc, math\n",
    "import numpy as np\n",
    "from scipy.fftpack import dct,idct\n",
    "from keras.datasets import cifar10\n",
    "from PIL import Image\n",
    "from multiprocessing import Pool\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from models.util import *\n",
    "\n",
    "\n",
    "#Seed used for choosing classes, training points, and test points.\n",
    "#SEED = 14\n",
    "SEED=11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 500\n",
    "sqrt_n = 32\n",
    "input_shape=(sqrt_n,sqrt_n)\n",
    "n = sqrt_n*sqrt_n\n",
    "k = 40\n",
    "c=2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Load Cifar10 data\n",
    "(X_train, _), (X_test, _) = cifar10.load_data()\n",
    "X_train = X_train.reshape(-1, 32, 32, 3)\n",
    "X_test = X_test.reshape(-1, 32, 32, 3)\n",
    "\n",
    "m_data = np.concatenate((X_train,X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize the data\n",
    "m_data = m_data/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check cifar10 results for 1000 random images - BP\n",
    "subset_idx = np.random.choice(np.arange(m_data.shape[0]),num_samples)\n",
    "m_data_sub_bp = m_data[subset_idx]\n",
    "m_data_y_bp = np.zeros((num_samples,sqrt_n,sqrt_n,3))\n",
    "for i in range(num_samples):\n",
    "    #first sample an element from the data\n",
    "    x = m_data_sub_bp[i,:,:,:].flatten()\n",
    "    e = np.random.uniform(size=n*3)\n",
    "    y = x + e\n",
    "    m_data_y_bp[i,:,:,:] = y.reshape((sqrt_n,sqrt_n,3))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Form the matrix F\n",
    "n = 32*32\n",
    "F = get_matrix(n,tf='dct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta_1 = 1.0\n",
    "eta_2 = np.linalg.norm(dct(np.ones(n), norm='ortho'), ord=np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approximate(z):\n",
    "    x_hat = dantzig(z,F.T,n=n,eta_1=eta_1,eta_2=eta_2 )\n",
    "    return x_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-9a1ad57d0c9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0my_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_g\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_b\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mapproximates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapproximate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    249\u001b[0m         '''\n\u001b[1;32m    250\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mRUN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mimap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/threading.pyc\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0m__debug__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_note\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s.wait(): got it\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%capture three\n",
    "#BP CIFAR10\n",
    "errors_l2_bp = np.zeros(m_data_y_bp.shape[0])\n",
    "errors_l1_bp = np.zeros(m_data_y_bp.shape[0])\n",
    "eta_bp = np.zeros((m_data_y_bp.shape[0],3))\n",
    "diff_l2_bp = np.zeros(m_data_y_bp.shape[0])\n",
    "diff_l1_bp = np.zeros(m_data_y_bp.shape[0])\n",
    "\n",
    "for i in range(num_samples):\n",
    "    y_r = m_data_y_bp[i,:,:,0].flatten()\n",
    "    x_r = m_data_sub_bp[i,:,:,0].flatten()\n",
    "    \n",
    "    #Get actual top k and bottom k\n",
    "    x_hat_r =  get_topk_vec(dct(x_r, norm='ortho'),k=k)  \n",
    "    \n",
    "    y_g = m_data_y_bp[i,:,:,1].flatten()\n",
    "    x_g = m_data_sub_bp[i,:,:,1].flatten()\n",
    "    \n",
    "    #Get actual top k and bottom k\n",
    "    x_hat_g =  get_topk_vec(dct(x_g, norm='ortho'),k=k)  \n",
    "    \n",
    "    \n",
    "    y_b = m_data_y_bp[i,:,:,2].flatten()\n",
    "    x_b = m_data_sub_bp[i,:,:,2].flatten()\n",
    "    \n",
    "    #Get actual top k and bottom k\n",
    "    x_hat_b =  get_topk_vec(dct(x_b, norm='ortho'),k=k)  \n",
    "    \n",
    "    args = [y_r, y_g,y_b]\n",
    "    p = Pool(3)\n",
    "    approximates = p.map(approximate, args)\n",
    "    p.terminate()\n",
    "\n",
    "    x_hat_approx_r = approximates[0]\n",
    "    x_hat_approx_g = approximates[1]\n",
    "    x_hat_approx_b = approximates[2]\n",
    "\n",
    "\n",
    "    #Note the errors\n",
    "    errors_l2_bp[i] = np.linalg.norm(x_hat_r.flatten()- x_hat_approx_r.flatten()) + \\\n",
    "                        np.linalg.norm(x_hat_g.flatten()- x_hat_approx_g.flatten()) + \\\n",
    "                            np.linalg.norm(x_hat_b.flatten()- x_hat_approx_b.flatten())\n",
    "    errors_l1_bp[i] = np.linalg.norm(x_hat_r.flatten()- x_hat_approx_r.flatten(),ord=1) + \\\n",
    "                        np.linalg.norm(x_hat_g.flatten()- x_hat_approx_g.flatten(),ord=1) + \\\n",
    "                            np.linalg.norm(x_hat_b.flatten()- x_hat_approx_b.flatten(),ord=1)\n",
    "\n",
    "\n",
    "\n",
    "    #Get the multiplicative constant\n",
    "    c_l2 = 6*np.sqrt(k)*eta_2\n",
    "    c_l1 = 4*k*eta_2\n",
    "    \n",
    "    \n",
    "    #Calculate the difference from the upper bound\n",
    "    diff_l2_bp[i] = 3*c_l2 - errors_l2_bp[i] \n",
    "    diff_l1_bp[i] = 3*c_l1 - errors_l1_bp[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.030799352119061457 7.255088376908885 0.2304279009777905 30.48957209902221\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(errors_l2_bp), \n",
    "      np.mean(diff_l2_bp), \n",
    "      np.mean(errors_l1_bp), \n",
    "      np.mean(diff_l1_bp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_norms = np.zeros(m_data_y_bp.shape)\n",
    "for i in range(num_samples):\n",
    "    y = m_data_y_bp[i,:,:,:].flatten()\n",
    "    x = m_data_sub_bp[i,:,:,:].flatten()\n",
    "    e_norms[i] = np.linalg.norm(y - x,ord=np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(e_norms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_tup_bp = (m_data_y_bp, m_data_sub_bp, errors_l2_bp, errors_l1_bp, diff_l2_bp, diff_l1_bp )\n",
    "\n",
    "import pickle\n",
    "with open('data/cifar_theory_socp_l2.pickle', 'wb') as f:\n",
    "    pickle.dump(mnist_tup_bp, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
