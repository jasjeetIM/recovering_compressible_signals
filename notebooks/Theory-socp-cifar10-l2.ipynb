{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BP Experiments to verify theory for L-2 norm - CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import sys, os, gc, math\n",
    "import numpy as np\n",
    "from scipy.fftpack import dct,idct\n",
    "from keras.datasets import cifar10\n",
    "from PIL import Image\n",
    "from multiprocessing import Pool\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from models.util import *\n",
    "\n",
    "\n",
    "#Seed used for choosing classes, training points, and test points.\n",
    "#SEED = 14\n",
    "SEED=11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 500\n",
    "sqrt_n = 32\n",
    "input_shape=(sqrt_n,sqrt_n)\n",
    "n = sqrt_n*sqrt_n\n",
    "k = 40\n",
    "c=2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Load Cifar10 data\n",
    "(X_train, _), (X_test, _) = cifar10.load_data()\n",
    "X_train = X_train.reshape(-1, 32, 32, 3)\n",
    "X_test = X_test.reshape(-1, 32, 32, 3)\n",
    "\n",
    "m_data = np.concatenate((X_train,X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize the data\n",
    "m_data = m_data/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check cifar10 results for 1000 random images - BP\n",
    "subset_idx = np.random.choice(np.arange(m_data.shape[0]),num_samples)\n",
    "m_data_sub_bp = m_data[subset_idx]\n",
    "m_data_y_bp = np.zeros((num_samples,sqrt_n,sqrt_n,3))\n",
    "for i in range(num_samples):\n",
    "    #first sample an element from the data\n",
    "    x = m_data_sub_bp[i,:,:,:].flatten()\n",
    "    x_hat = dct(x,norm='ortho')\n",
    "    x_k = idct(get_topk_vec(x_hat,k=k),norm='ortho')\n",
    "    e = np.random.uniform(size=n*3)\n",
    "    y = x_k + e\n",
    "    m_data_y_bp[i,:,:,:] = y.reshape((sqrt_n,sqrt_n,3))  \n",
    "    m_data_sub_bp[i,:,:,:] = x_k.reshape((sqrt_n,sqrt_n,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Form the matrix F\n",
    "F = get_matrix(n,tf='dct')\n",
    "n = 32*32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approximate(z):\n",
    "    y,eta = z\n",
    "    x_hat = socp(y,F,n=n,eta=eta)\n",
    "    return x_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture three\n",
    "#BP CIFAR10\n",
    "errors_l2_bp = np.zeros(m_data_y_bp.shape[0])\n",
    "errors_l1_bp = np.zeros(m_data_y_bp.shape[0])\n",
    "eta_bp = np.zeros((m_data_y_bp.shape[0],3))\n",
    "diff_l2_bp = np.zeros(m_data_y_bp.shape[0])\n",
    "diff_l1_bp = np.zeros(m_data_y_bp.shape[0])\n",
    "\n",
    "for i in range(num_samples):\n",
    "    y_r = m_data_y_bp[i,:,:,0].flatten()\n",
    "    x_r = m_data_sub_bp[i,:,:,0].flatten()\n",
    "    \n",
    "    #Get actual top k and bottom k\n",
    "    x_hat_top_k_r = dct(x_r, norm='ortho')\n",
    "    \n",
    "    e_r = y_r - x_r\n",
    "    eta_r = eta_bp[i,0] = np.linalg.norm(e_r)\n",
    "    \n",
    "    y_g = m_data_y_bp[i,:,:,1].flatten()\n",
    "    x_g = m_data_sub_bp[i,:,:,1].flatten()\n",
    "    \n",
    "    #Get actual top k and bottom k\n",
    "    x_hat_top_k_g = dct(x_g, norm='ortho') \n",
    "    \n",
    "    e_g = y_g - x_g\n",
    "    eta_g = eta_bp[i,1] = np.linalg.norm(e_g)\n",
    "    \n",
    "    \n",
    "    y_b = m_data_y_bp[i,:,:,2].flatten()\n",
    "    x_b = m_data_sub_bp[i,:,:,2].flatten()\n",
    "    \n",
    "    #Get actual top k and bottom k\n",
    "    x_hat_top_k_b =  dct(x_b, norm='ortho') \n",
    "    \n",
    "    e_b = y_b - x_b\n",
    "    eta_b = eta_bp[i,2] = np.linalg.norm(e_b)\n",
    "    \n",
    "    args = [(y_r,eta_r), (y_g,eta_g), (y_b,eta_b)]\n",
    "    p = Pool(3)\n",
    "    approximates = p.map(approximate, args)\n",
    "    p.terminate()\n",
    "\n",
    "    x_hat_approx_r = approximates[0]\n",
    "    x_hat_approx_g = approximates[1]\n",
    "    x_hat_approx_b = approximates[2]\n",
    "\n",
    "    \n",
    "    #Note the errors\n",
    "    errors_l2_bp[i] = np.linalg.norm(x_hat_top_k_r.flatten()- x_hat_approx_r.flatten()) + \\\n",
    "                        np.linalg.norm(x_hat_top_k_g.flatten()- x_hat_approx_g.flatten()) + \\\n",
    "                            np.linalg.norm(x_hat_top_k_b.flatten()- x_hat_approx_b.flatten())\n",
    "    errors_l1_bp[i] = np.linalg.norm(x_hat_top_k_r.flatten()- x_hat_approx_r.flatten(),ord=1) + \\\n",
    "                        np.linalg.norm(x_hat_top_k_g.flatten()- x_hat_approx_g.flatten(),ord=1) + \\\n",
    "                            np.linalg.norm(x_hat_top_k_b.flatten()- x_hat_approx_b.flatten(),ord=1)\n",
    "\n",
    "\n",
    "\n",
    "    #Get the multiplicative constant\n",
    "    c_l2_r = 6*eta_bp[i,0]\n",
    "    c_l1_r = np.sqrt(k)*6*eta_bp[i,0]\n",
    "    c_l2_g = 6*eta_bp[i,1]\n",
    "    c_l1_g = np.sqrt(k)*6*eta_bp[i,1]\n",
    "    c_l2_b = 6*eta_bp[i,2]\n",
    "    c_l1_b = np.sqrt(k)*6*eta_bp[i,2]\n",
    "    \n",
    "    \n",
    "    #Calculate the difference from the upper bound\n",
    "    diff_l2_bp[i] = c_l2_r + c_l2_g + c_l2_b - errors_l2_bp[i] \n",
    "    diff_l1_bp[i] = c_l1_r + c_l1_g + c_l1_b - errors_l1_bp[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.454773209090032 315.222592295217 88.5623598605005 2015.4740420953808\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(errors_l2_bp), \n",
    "      np.mean(diff_l2_bp), \n",
    "      np.mean(errors_l1_bp), \n",
    "      np.mean(diff_l1_bp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_norms = np.zeros(m_data_y_bp.shape)\n",
    "for i in range(num_samples):\n",
    "    y = m_data_y_bp[i,:,:,:].flatten()\n",
    "    x = m_data_sub_bp[i,:,:,:].flatten()\n",
    "    e_norms[i] = np.linalg.norm(y - x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.01397038302063"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(e_norms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_tup_bp = (m_data_y_bp, m_data_sub_bp, errors_l2_bp, errors_l1_bp, diff_l2_bp, diff_l1_bp )\n",
    "\n",
    "import pickle\n",
    "with open('data/cifar_theory_socp_l2.pickle', 'wb') as f:\n",
    "    pickle.dump(mnist_tup_bp, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
